{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marconiadsf/Desafio-4---I2A2/blob/main/Desafio4v11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DESAFIO 4 - Versão 11**\n",
        "\n",
        "**Como usar:**\n",
        "1) Faça upload desse arquivo e abra no seu google Colab\n",
        "2) No icone da pasta ao lado suba os arquivos exceto o VR MENSAL 05.2025.xlsx\n",
        "3) Crie uma APY KEY do Google e a variável de ambiente no icone de chave ai do lado. A variável deve se chamar: GOOGLE_API_KEY\n",
        "4) Clique em Executar tudo na barra superior abaixo de ambiente de execução.\n",
        "O arquivo VR MENSAL 05.2025.xlsx será criado na mesma pasta ao lado."
      ],
      "metadata": {
        "id": "f2zFVh3APL3G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCCbECexLk_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2695514-dda3-4770-8bd9-4ed8da6745a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installation complete.\n"
          ]
        }
      ],
      "source": [
        "!pip install google-adk -q\n",
        "!pip install litellm -q\n",
        "!pip install unidecode -q\n",
        "print(\"Installation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import necessary libraries\n",
        "import os\n",
        "import asyncio\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.genai import types # For creating message Content/Parts\n",
        "\n",
        "import pandas as pd\n",
        "from pandas.tseries.offsets import MonthEnd\n",
        "import numpy as np\n",
        "import time\n",
        "from unidecode import unidecode\n",
        "from typing import List\n",
        "from typing import Dict, Any\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "\n",
        "\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "print(\"Libraries imported.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4s-fk4ziQNK",
        "outputId": "45767dfd-113c-45ca-9839-7c22433f1446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfCqHo1tLk8P"
      },
      "outputs": [],
      "source": [
        "# Configura a API Key do Google Gemini\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV4w0H5TLk5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf02395-630a-4797-95d1-d84a779e7d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Environment configured.\n"
          ]
        }
      ],
      "source": [
        "# --- Define Model Constants for easier use ---\n",
        "\n",
        "# More supported models can be referenced here: https://ai.google.dev/gemini-api/docs/models#model-variations\n",
        "MODEL_GEMINI_2_5_FLASH = \"gemini-2.5-flash\"\n",
        "\n",
        "\n",
        "print(\"\\nEnvironment configured.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define the dataframe tools\n",
        "def criarColunaRegex(\n",
        "    df_name: str,\n",
        "    src_column_name: str,\n",
        "    new_column_name: str,\n",
        "    lista_de_strings: List[str]\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Extrai padrões de texto de uma coluna (especificada por nome) usando regex gerado a partir de uma lista de strings.\n",
        "\n",
        "    Args:\n",
        "        df_name (str): Nome do DataFrame no DataFrameManager.\n",
        "        src_column_name (str): Nome da coluna de origem.\n",
        "        new_column_name (str): Nome da nova coluna a ser criada.\n",
        "        lista_de_strings (List[str]): Lista de padrões a serem extraídos (ex: siglas de estados).\n",
        "\n",
        "    Returns:\n",
        "        dict: {\"status\": \"success\", \"df_name\": <nome>, \"error\": None} ou {\"status\": \"error\", ...}\n",
        "    \"\"\"\n",
        "    df = DataFrameManager.get(df_name)\n",
        "    if df is None:\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"df_name\": None,\n",
        "            \"error\": f\"DataFrame '{df_name}' não encontrado.\"\n",
        "        }\n",
        "\n",
        "    if src_column_name not in df.columns:\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"df_name\": None,\n",
        "            \"error\": f\"Coluna '{src_column_name}' não existe em '{df_name}'.\"\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        # Monta o regex a partir da lista\n",
        "        padrao = r\"\\b(\" + \"|\".join(re.escape(s) for s in lista_de_strings) + r\")\\b\"\n",
        "\n",
        "        # Aplica a extração com conversão segura para string\n",
        "        df[new_column_name] = df[src_column_name].astype(str).str.extract(padrao, expand=False)\n",
        "\n",
        "        DataFrameManager.update({df_name: df})\n",
        "        return {\"status\": \"success\", \"df_name\": df_name, \"error\": None}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"df_name\": None,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "def mapearValoresColunaNome(\n",
        "    df_name: str,\n",
        "    coluna_origem: str,\n",
        "    coluna_destino: str,\n",
        "    mapa_valores: Dict[Any, Any]\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Cria uma nova coluna em um DataFrame com base no mapeamento de valores da coluna existente.\n",
        "\n",
        "    Args:\n",
        "        df_name (str): Nome do DataFrame no DataFrameManager.\n",
        "        coluna_origem (str): Nome da coluna a ser usada como base.\n",
        "        coluna_destino (str): Nome da nova coluna a ser criada.\n",
        "        mapa_valores (Dict[Any, Any]): Dicionário de mapeamento {valor_original: valor_novo}.\n",
        "\n",
        "    Returns:\n",
        "        dict: {\"status\": \"success\", \"df_name\": <nome>, \"error\": None} ou {\"status\": \"error\", ...}\n",
        "    \"\"\"\n",
        "    df = DataFrameManager.get(df_name)\n",
        "    if df is None:\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"df_name\": None,\n",
        "            \"error\": f\"DataFrame '{df_name}' não encontrado.\"\n",
        "        }\n",
        "\n",
        "    if coluna_origem not in df.columns:\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"df_name\": None,\n",
        "            \"error\": f\"Coluna '{coluna_origem}' não existe em '{df_name}'.\"\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        df[coluna_destino] = df[coluna_origem].map(mapa_valores)\n",
        "        DataFrameManager.update({df_name: df})\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"df_name\": df_name,\n",
        "            \"error\": None\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"df_name\": None,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "def mapearValoresColunaIndex(\n",
        "    df_name: str,\n",
        "    coluna_origem_index: int,\n",
        "    coluna_destino: str,\n",
        "    mapa_valores: Dict[Any, Any]\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Cria uma nova coluna em um DataFrame com base no mapeamento de valores da coluna existente.\n",
        "\n",
        "    Args:\n",
        "        df_name (str): Nome do DataFrame no DataFrameManager.\n",
        "        coluna_origem_index (int): Índice da coluna a ser usada como base.\n",
        "        coluna_destino (str): Nome da nova coluna a ser criada.\n",
        "        mapa_valores (Dict[Any, Any]): Dicionário de mapeamento {valor_original: valor_novo}.\n",
        "\n",
        "    Returns:\n",
        "        dict: {\"status\": \"success\", \"df_name\": <nome>, \"error\": None} ou {\"status\": \"error\", ...}\n",
        "    \"\"\"\n",
        "    df = DataFrameManager.get(df_name)\n",
        "    if df is None:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": f\"DataFrame '{df_name}' não encontrado.\"}\n",
        "\n",
        "    try:\n",
        "        # Verifica se o índice da coluna é válido\n",
        "        if coluna_origem_index < 0 or coluna_origem_index >= len(df.columns):\n",
        "            return {\"status\": \"error\", \"df_name\": None, \"error\": f\"Índice de coluna inválido: {coluna_origem_index}\"}\n",
        "\n",
        "        coluna_origem = df.columns[coluna_origem_index]\n",
        "\n",
        "        # Aplica o mapeamento\n",
        "        df[coluna_destino] = df[coluna_origem].map(mapa_valores)\n",
        "\n",
        "        # Atualiza o DataFrame\n",
        "        DataFrameManager.update({df_name: df})\n",
        "        return {\"status\": \"success\", \"df_name\": df_name, \"error\": None}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": str(e)}\n",
        "\n",
        "def querydataframe(query: str, df_name: str, variables: dict) -> dict:\n",
        "    \"\"\"Executa uma query sobre um DataFrame usando pandas.query, com suporte a variáveis externas.\n",
        "\n",
        "    Args:\n",
        "        query (str): A string com a operação a ser realizada no dataframe.\n",
        "        df_name (str): O nome do dataframe a ser utilizado.\n",
        "        variables (dict, opcional): Dicionário com variáveis externas à query.\n",
        "        verbose (bool, opcional): Se True, imprime logs de execução.\n",
        "\n",
        "    Retorna:\n",
        "        dict: Um dicionário com o resultado da query.\n",
        "              Inclui uma chave 'status' ('success' ou 'error').\n",
        "              Se 'success', inclui o nome do dataframe resultante na chave 'df_name' e None na chave 'error'.\n",
        "              Se 'error', a chave 'df_name' é None e 'error' contém a mensagem de erro.\n",
        "    \"\"\"\n",
        "    if variables is None:\n",
        "      variables = {}\n",
        "    df = DataFrameManager.get(df_name)\n",
        "    if df is None:\n",
        "        #print(f\"--- Tool: querydataframe called: No dataframe {df_name} avaiable ---\")\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": \"DataFrame does not exist.\"}\n",
        "\n",
        "    #print(f\"--- Tool: querydataframe called for dataframe: {df_name} ---\")\n",
        "\n",
        "    try:\n",
        "        result = df.query(query, local_dict=variables)\n",
        "        DataFrameManager.update({df_name: result})\n",
        "        return {\"status\": \"success\", \"df_name\": df_name, \"error\": None}\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": str(e)}\n",
        "\n",
        "def evaldataframe(expression: str, df_name: str, variables: dict) -> dict:\n",
        "    \"\"\"Executa uma expressão sobre o dataframe, através do método eval com suporte a variáveis externas.\n",
        "\n",
        "    Args:\n",
        "        code (str): A string com o código a ser executado.\n",
        "        df_name (str): O nome do dataframe a ser utilizado.\n",
        "\n",
        "    Retorna:\n",
        "        dict: Um dicionário com o resultado da query.\n",
        "              Inclui uma chave de 'status' ('success' or 'error').\n",
        "              Se 'success', inclui o nome do dataframe resultante na chave 'df_name' e None na chave 'error'.\n",
        "              Se 'error', a chave 'df_name' é None e 'error' contém a mensagem de erro.\n",
        "    \"\"\"\n",
        "    if variables is None:\n",
        "      variables = {}\n",
        "    df = DataFrameManager.get(df_name)\n",
        "    if df is None:\n",
        "        #    print(f\"--- Tool: evaldataframe called: No dataframe {df_name} available ---\")\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": \"DataFrame does not exist.\"}\n",
        "\n",
        "    #print(f\"--- Tool: evaldataframe called for dataframe: {df_name} ---\")\n",
        "\n",
        "    try:\n",
        "        result = df.eval(expr=expression, local_dict=variables)\n",
        "        #new_df_name = f\"{df_name}_newquery_{int(time.time())}\"\n",
        "        DataFrameManager.update({df_name: result})\n",
        "        return {\"status\": \"success\", \"df_name\": df_name, \"error\": None}\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": str(e)}\n",
        "\n",
        "def getdataframenames() -> list:\n",
        "    return list(DataFrameManager.keys())\n",
        "\n",
        "def getdataframeheader(df_name: str) -> dict:\n",
        "    df = DataFrameManager.get(df_name)\n",
        "    if df is None:\n",
        "        return {}\n",
        "    header = {col: str(dtype) for col, dtype in df.dtypes.items()}\n",
        "    return  header\n",
        "\n",
        "def getdataframestdjheader(df_name: str) -> str:\n",
        "    df = DataFrameManager.get(df_name)\n",
        "    if df is None:\n",
        "        return {}\n",
        "    header = df.head(5).to_json(orient=\"records\", lines=True)\n",
        "    return  header\n",
        "\n",
        "def getdataframestdmheader(df_name: str) -> str:\n",
        "    df = DataFrameManager.get(df_name)\n",
        "    if df is None:\n",
        "        return {}\n",
        "    header = df.head(5).to_markdown()\n",
        "    return  header\n",
        "\n",
        "def adicionarDescricao(df_name: str, title: str, description: str) -> dict:\n",
        "    df = DataFrameManager.get(df_name)\n",
        "    if df is None:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": \"DataFrame does not exist.\"}\n",
        "    df.__setattr__('title', title)\n",
        "    df.__setattr__('description', description)\n",
        "    return {\"status\": \"success\", \"df_name\": df_name, \"error\": None}\n",
        "\n",
        "def copiarColunaSimples(dest_df_name: str, src_df_name: str, dest_column_name: str, src_column_name: str) -> dict:\n",
        "    \"\"\"\n",
        "    Copia os valores da coluna do DataFrame `src_df_name`\n",
        "    e define como índice do DataFrame `dest_df_name`.\n",
        "\n",
        "    Requisitos:\n",
        "    - Ambos os DataFrames devem existir no DataFrameManager.\n",
        "    - A coluna de matrícula deve existir no DataFrame de origem.\n",
        "\n",
        "    Retorna:\n",
        "        dict: {\"status\": \"success\", \"df_name\": <nome_do_df_destino>, \"error\": None}\n",
        "              ou {\"status\": \"error\", \"df_name\": None, \"error\": <mensagem>}\n",
        "    \"\"\"\n",
        "    df_dest = DataFrameManager.get(dest_df_name)\n",
        "    df_src = DataFrameManager.get(src_df_name)\n",
        "\n",
        "    if df_dest is None or df_src is None:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": \"Um ou ambos os DataFrames não existem.\"}\n",
        "\n",
        "    if src_column_name not in df_src.columns:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": f\"Coluna '{src_column_name}' não encontrada em '{src_df_name}'.\"}\n",
        "\n",
        "    try:\n",
        "        # Define o índice do DataFrame destino com os valores da coluna de matrícula\n",
        "\n",
        "        df_dest[dest_column_name] = df_src[src_column_name].values\n",
        "        # Atualiza o DataFrame no DataFrameManager\n",
        "        DataFrameManager[dest_df_name] = df_dest\n",
        "\n",
        "        return {\"status\": \"success\", \"df_name\": dest_df_name, \"error\": None}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": str(e)}\n",
        "\n",
        "\n",
        "def copiarColunaAdicionando(dest_df_name, src_df_name, dest_column_name, src_column_name):\n",
        "    \"\"\"\n",
        "    Copia os valores da coluna src_column_name do DataFrame src_df_name\n",
        "    e os adiciona abaixo da coluna dest_column_name do DataFrame dest_df_name.\n",
        "\n",
        "    Requisitos:\n",
        "    - Ambos os DataFrames devem existir no DataFrameManager.\n",
        "    - Ambas as colunas devem existir nos respectivos DataFrames.\n",
        "\n",
        "    O resultado é um novo DataFrame com a coluna dest_column_name expandida,\n",
        "    contendo os dados originais seguidos dos dados da coluna src_column_name.\n",
        "\n",
        "    Retorna:\n",
        "        dict: {\"status\": \"success\", \"newdf\": <nome_do_novo_df>, \"error\": None}\n",
        "              ou {\"status\": \"error\", \"newdf\": None, \"error\": <mensagem>}\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Recupera os DataFrames\n",
        "    dest_df = DataFrameManager.get(dest_df_name)\n",
        "    src_df = DataFrameManager.get(src_df_name)\n",
        "\n",
        "    if dest_df is None or src_df is None:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": \"Um ou ambos os DataFrames não existem.\"}\n",
        "\n",
        "    # Verifica se as colunas existem\n",
        "    if dest_column_name not in dest_df.columns:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": f\"Coluna '{dest_column_name}' não encontrada em '{dest_df_name}'.\"}\n",
        "    if src_column_name not in src_df.columns:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": f\"Coluna '{src_column_name}' não encontrada em '{src_df_name}'.\"}\n",
        "\n",
        "    try:\n",
        "        # Extrai as colunas como Series\n",
        "        coluna_dest = dest_df[dest_column_name]\n",
        "        coluna_src = src_df[src_column_name]\n",
        "\n",
        "        # Concatena verticalmente\n",
        "        coluna_combinada = pd.concat([coluna_dest, coluna_src], ignore_index=True)\n",
        "\n",
        "        # Atualiza a coluna no DataFrame de destino\n",
        "        dest_df_expanded = dest_df.copy()\n",
        "        dest_df_expanded = dest_df_expanded.reindex(range(len(coluna_combinada)))\n",
        "        dest_df_expanded[dest_column_name] = coluna_combinada\n",
        "\n",
        "        # Atualiza o DataFrame no DataFrameManager\n",
        "        DataFrameManager[dest_df_name] = dest_df_expanded\n",
        "\n",
        "        return {\"status\": \"success\", \"newdf\": dest_df_name, \"error\": None}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"newdf\": None, \"error\": str(e)}\n",
        "\n",
        "\n",
        "def fundirColunaBaseIndexador(df_dest_name: str, df_src_name: str, index_column_name: str, column_name_list: List[str]) -> dict:\n",
        "    dfdest = DataFrameManager.get(df_dest_name)\n",
        "    dfsource = DataFrameManager.get(df_src_name)\n",
        "\n",
        "    if dfdest is None:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": \"DataFrame does not exist.\"}\n",
        "    if dfsource is None:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": \"DataFrame does not exist.\"}\n",
        "\n",
        "    try:\n",
        "        # Garante que todas as colunas existem no dfsource\n",
        "        colunas_para_copiar = [index_column_name] + column_name_list\n",
        "        for col in colunas_para_copiar:\n",
        "            if col not in dfsource.columns:\n",
        "                return {\"status\": \"error\", \"df_name\": None, \"error\": f\"Coluna '{col}' não encontrada em '{df_src_name}'.\"}\n",
        "\n",
        "        # Executa o merge\n",
        "        dfdest = pd.merge(\n",
        "            dfdest,\n",
        "            dfsource[colunas_para_copiar],\n",
        "            on=index_column_name,\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        DataFrameManager.update({df_dest_name: dfdest})\n",
        "        return {\"status\": \"success\", \"df_name\": df_dest_name, \"error\": None}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": str(e)}\n",
        "\n",
        "def padronizarNomes():\n",
        "  # Strip all whitespace from all column names in the DataFrames\n",
        "  for key, df in DataFrameManager.items():\n",
        "     df.columns = [unidecode(col.strip()).upper() for col in df.columns]\n",
        "\n",
        "def removerLixoCabecalhos(df_name: str) -> dict:\n",
        "  df = DataFrameManager.get(df_name)\n",
        "  if df is None:\n",
        "    return {\"status\": \"error\", \"df_name\": None, \"error\": \"DataFrame does not exist.\"}\n",
        "  # Remove linhas com lixo no começo de um dataframe transformando a segunda linha em cabeçalho.\n",
        "  df.columns = df.iloc[0]  # Usa a segunda linha como cabeçalho\n",
        "  df = df.iloc[1:].reset_index(drop=True)  # Remove as duas primeiras linhas e reseta o índice\n",
        "  DataFrameManager.update({df_name: df})\n",
        "  return {\"status\": \"success\", \"df_name\": df_name, \"error\": None}\n",
        "\n",
        "def renameColumn(df_name: str, name_dict: dict) -> dict:\n",
        "  df = DataFrameManager.get(df_name)\n",
        "  if df is None:\n",
        "    return {\"status\": \"error\", \"df_name\": None, \"error\": \"DataFrame does not exist.\"}\n",
        "  df.rename(columns=name_dict, inplace=True)\n",
        "  return {\"status\": \"success\", \"df_name\": df_name, \"error\": None}"
      ],
      "metadata": {
        "id": "2MnvxT-j2XuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "operadorDataFrameInstrucoes = \"\"\"\n",
        "Você é um analista de dados experiente em uma equipe colaborativa.\n",
        "\n",
        "Objetivo:\n",
        "- Responder solicitações sobre DataFrames usando exclusivamente as ferramentas: querydataframe, evaldataframe, getdataframenames e getdataframeheader.\n",
        "- Retornar apenas um dicionário no formato padrão da equipe. Não inclua explicações textuais.\n",
        "\n",
        "Formato padrão de resposta e outras regras:\n",
        "- Sucesso: {\"status\": \"success\", \"newdf\": \"<nome_do_dataframe_resultante>\", \"error\": None}\n",
        "- Erro: {\"status\": \"error\", \"newdf\": None, \"error\": \"<mensagem_de_erro>\", \"attempts\": [...]}  # \"attempts\" é opcional e lista as tentativas de correção.\n",
        "- Todos os nomes de colunas criadas deverão ser maiúsculas.\n",
        "\n",
        "\n",
        "Ferramentas:\n",
        "- querydataframe(query: str, df_name: str, variables: dict)\n",
        "  Use para filtros/seleção de linhas via expressões booleanas (pandas.query).\n",
        "- evaldataframe(expression: str, df_name: str, variables: dict)\n",
        "  Use para criar/modificar colunas via expressões matemáticas/lógicas (pandas.eval).\n",
        "- criarColunaRegex(df_name: str,src_column_name: src,new_column_name: str,lista_de_strings: List[str])\n",
        "  Uma função capaz de criar uma nova coluna, com base numa busca regex da src_column_name, pela string ou strings em lista_de_strings\n",
        "- mapearValoresColunaNome(df_name: str,coluna_origem: str,coluna_destino: str,mapa_valores: Dict[Any, Any])\n",
        "  Essa função recebe um coluna do dataframe selecionado e cria uma nova coluna com base no mapeamento de valores.\n",
        "- getdataframenames()\n",
        "  Retorna uma lista simples com os nomes dos DataFrames disponíveis.\n",
        "- getdataframeheader(df_name: str)\n",
        "  Retorna um dict com nomes de colunas e tipos do DataFrame informado.\n",
        "\n",
        "Variáveis externas:\n",
        "- Dentro de query/expression, variáveis externas devem ser referenciadas com @ (ex.: Fee > @min_fee).\n",
        "- Sempre passe o dicionário \"variables\" correspondente (ex.: {\"min_fee\": 23000}).\n",
        "\n",
        "Resolução do nome do DataFrame (obrigatório antes de operar):\n",
        "1) Consulte a ferramenta getdataframenames()\n",
        "2) Verifique se o nome que o usuário citou de dataframe ou tabela está presente na lista e o use.\n",
        "3) Se o dataframe for inexiste repasse o erro sem inventar resultados.\n",
        "4) Jamais tente acessar DataFrames diretamente; sempre use os nomes e as ferramentas.\n",
        "\n",
        "Seleção de ferramenta:\n",
        "- Use querydataframe para filtrar/selecionar linhas (condições booleanas).\n",
        "- Use evaldataframe para criar/modificar colunas ou realizar cálculos.\n",
        "- Combine variáveis externas com @ quando necessário.\n",
        "\n",
        "Casos especiais:\n",
        "- Para criação de colunas com busca regex, ou mencionado algo como extracao de uma valor de uma coluna use a ferramenta criarColunaRegex.\n",
        "  Exemplo: criarColunaRegex(\"DataframeDestino\",\"ColunaFonte\",\"NovaColuna\",[\"Foo\", \"Bar\", \"Fee\", \"Beer\"])\n",
        "  Ela extraí o valor da coluna fonte selecionada e cria uma nova coluna\n",
        "- Se for solicitado para criar uma coluna com base nos valores de outra coluna use mapear_valores_em_coluna.\n",
        "  Exemplo: mapearValoresColunaNome(\"DataframeDestino\",\"ColunaFonte\",\"NovaColuna\",{\"Foo\": 1, \"Bar\": 2, \"Fee\": 3, \"Beer\": 4})\n",
        "  Você deve criar o dicionário com base na requisição do usuário.\n",
        "\n",
        "Resoluçao de consultas, erros e regras para reiterações de consultas (até 3 tentativas):\n",
        "\n",
        "1) Consulte os nomes das colunas do dataframe com getdatraframeheader()\n",
        "2) Verifique se usuário faz uma menção especifica a nome de coluna ela está na lista. Se não tente deduzir a coluna mais provável usando a seguinte lógica:\n",
        "    - Busque o nome mais próximo por similaridade óbvia (ex.: Vemdas -> Vendas), incluindo:\n",
        "     * Correção de acentos e pequenas trocas de letras, minúsculas e maiúsculas.\n",
        "     * Se não houver candidato plausível, retorne um erro.\n",
        "     LEMBRETE: O erro pode ser tant ode digitação do usuário quanto da planilha original.\n",
        "3) Faça a consulta na coluna inferida usando a ferramenta apropriada\n",
        "4) Em caso de erro:\n",
        "  - Se o erro indicar problema na query/expression (ex.:sintaxe inválida):\n",
        "     --Ajuste a query/expression (use notnull()/isnull(), operadores válidos, etc.) - lembre-se que getdatraframeheader() retorna também os tipos de dados.\n",
        "  - Tente refazer a chamada com as correções até 3 vezes no total.\n",
        "  - Registre cada tentativa falha no campo \"attempts\": [{\"tool\": \"...\", \"error\": \"...\"}, ...].\n",
        "  - Após 3 tentativas sem sucesso, retorne o último erro.\n",
        "\n",
        "Boas práticas de query/expression:\n",
        "- Para nulos, use isnull() e notnull().\n",
        "- Prefira referências claras de coluna e parênteses em expressões compostas.\n",
        "- Toda variável externa deve usar @ e estar em \"variables\".\n",
        "\n",
        "Exemplos:\n",
        "- Filtro por taxa mínima:\n",
        "  querydataframe(\"Fee > @min_fee\", \"Cursos\", variables={\"min_fee\": 23000})\n",
        "- Nova coluna com desconto adicional:\n",
        "  evaldataframe(\"final_fee = (Fee - Discount) * (1 - @extra_discount)\", \"Cursos\", variables={\"extra_discount\": 0.05})\n",
        "\n",
        "Resposta:\n",
        "- Sempre retorne exclusivamente o dicionário no formato padrão.\n",
        "Observação importante:\n",
        "- Mesmo que a solicitação pareça pedir um único valor (ex.: preço de um curso, nome de um cliente), considere isso como uma solicitação de filtragem do DataFrame.\n",
        "Use a ferramenta apropriada para retornar um novo DataFrame contendo essas informações. Não trate esses casos como erro.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3GntY1z2LrhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descritorDataFrameInstrucoes = \"\"\"\n",
        "Você é um analista de dados experiente em uma equipe colaborativa.\n",
        "\n",
        "Objetivo:\n",
        "Utilize suas ferramentas para gerar descrições sobre um dataframe.\n",
        "Descubra quantos dataframes devem ser analisados usando a ferramenta getdataframenames: essa ferramenta retorna uma lista com os nomes dos dataframes disponíveis.\n",
        "Analise o cabeçalho de cada dataframe e o tipo de dados com a ferramenta getdataframeheader: Essa ferramenta retorna um dicionário com os nomes das colunas e seus tipos.\n",
        "De acordo com os nomes de colunas encontradas e tipos de dados tende determinar do que se trata o dataframe com uma frase simples.\n",
        "Utilize o prompt de entrada para mais contexto.\n",
        "\n",
        "Descrição das ferramentas:\n",
        "\n",
        "- getdataframenames()\n",
        "  Retorna uma lista simples com os nomes dos DataFrames disponíveis.\n",
        "- getdataframeheader(df_name: str)\n",
        "  Retorna um dict com nomes de colunas e tipos do DataFrame informado.\n",
        "- adicionarDescricao(df_name: str, title: str, description: str)\n",
        "  Adiciona um titulo e uma descrição ao dataframe. Retorna:\n",
        "  - {\"status\": \"error\", \"newdf\": None, \"error\": \"DataFrame does not exist.\"} em caso de erro ou\n",
        "  - {\"status\": \"success\", \"newdf\": df_name, \"error\": None} em caso de sucesso.\n",
        "\n",
        "Exemplos:\n",
        "  Prompt de entrada de alguem da equipe: \"Analise esses folhas de dados de vales refeiçao.\"\n",
        "  Suas ações:\n",
        "  1. Chamar getdataframesnames(). Retorno da função (exemplo): ['Ativos','Sindicatos','Demitidos','Admitidos Abril' ]\n",
        "  2. Chamar getdataframeheader('Ativos'). Retorno da função (exemplo): {'Matricula': 'int64','Cargo': 'object','Sindicato': 'object', 'Situacao': 'object', 'Unammed1': 'object'}\n",
        "  3. Com base nessa informação você pode inferir corretamente que estamos falando de um dataframe que, dados o prompt sobre vales refeição, provavelmente descreve uma lista de\n",
        "  colaboradores ativos de uma empresa contendo informações como matrícula, cargo, sindicato, situação e uma coluna não nomeada.\n",
        "  4. Crie um titulo e uma descriçao para o dataframe derivados de sua análise. Mantenha o titulo até 32 caracteres e a descricao até 200 caracteres.\n",
        "  5. Terminada a análise voce deve chamar a funcao _____(df_name,title,description) para reportar sua análise. Para o exemplo acima ficaria:\n",
        "    _____('Ativos','Lista de Funcionarios Ativos','Lista de colaboradores ativos. Contém as informações: matrícula, cargo, sindicato, situação e uma coluna não nomeada.')\n",
        "  6. Você deve fazer isso para os demais dataframes retornados pela função getdataframesnames().\n",
        "  7. Não tente acessar dataframes por sua conta, utilize apenas essas ferramentas.\n",
        "  8. Seja fiel ao conteúdo e não invente. Se uma planilha não contiver dados que ajudem a identifica-la frente ao contexto, seja sincero como por exemplo:\n",
        "    \"Planilha com dados não (estruturados/nomeados/identificados) dentro do contexto de vale refeição. Possui colunas: numérica(int64), string?(objeto)\"\n",
        "  9. Observe que o a instrucão 8 serve para quando a função getdataframeheader retornar valores estranhos de uma planilha nao formatada.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "08lmvVuonDNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatadorInstrucoes = \"\"\"\n",
        "Você é um analista de dados experiente e disciplinado, responsável por padronizar colunas de DataFrames com base em instruções explícitas do usuário.\n",
        "\n",
        "Seu papel é executar, não interpretar.\n",
        "\n",
        "Objetivo:\n",
        "Padronizar os nomes de colunas dos DataFrames disponíveis, corrigindo erros de digitação, inconsistências e variações semânticas.\n",
        "\n",
        "Ferramentas disponíveis:\n",
        "padronizarnomes() Limpa espaços, acentos, caracteres especiais e padroniza para maiúsculas em todos os DataFrames.\n",
        "removerLixoCabecalhos(df_name: str) - Remove linhas com lixo no começo de um dataframe transformando a segunda linha em cabeçalho. Cuidado, só chame essa função quando um cabeçalho paracer uma tabela pouco ou mal estruturada\n",
        "getdataframenames() Retorna os nomes dos DataFrames disponíveis.\n",
        "\n",
        "getdataframeheader(df_name) Retorna os nomes e tipos das colunas.\n",
        "\n",
        "getdataframestdmheader(df_name) Retorna as primeiras 5 linhas em formato markdown.\n",
        "\n",
        "renameColumn(df_name, name_dict) Renomeia colunas com base em um dicionário de equivalência.\n",
        "\n",
        "Regras obrigatórias:\n",
        "Execute padronizarnomes() antes de qualquer inspeção.\n",
        "\n",
        "Use getdataframenames() para listar os DataFrames disponíveis.\n",
        "\n",
        "Para cada DataFrame:\n",
        "\n",
        "Use getdataframeheader() e getdataframestdmheader() para entender a estrutura.\n",
        "\n",
        "Se o cabeçalho estiver ilegível ou não confiável, por exemplo, com colunas que indiquem um campo numérico mas o primeiro item observado é texto,\n",
        "utilize a removerLixoCabecalhos(nome do dataframe), pois pode ser que a primeira linha contenha lixo e a segunda seja o cabeçalho real.\n",
        "\n",
        "Renomeie colunas com base nas instruções do usuário, usando renameColumn():\n",
        "Exemplos:\n",
        "Colunas como CADASTRO, CADASTRO FUNCIONAL, CADASTRO DO FUNCIONARIO, CADASTRO DE PESSOAL, REGISTRO, MATRICULA FUNCIONAL → devem ser renomeadas para \"MATRICULA\".\n",
        "\n",
        "Colunas como TITULO DO CARGO, CARGO, FUNÇÃO, DESIGNAÇÃO, NOME DO CARGO → devem ser renomeadas para \"CARGO\".\n",
        "\n",
        "Não use acentos ou caracteres especiais nos nomes finais.\n",
        "\n",
        "Corrija proativamente pequenos erros de digitação nos cabeçalhos como: VEMDAS -> VENDAS, SINDICADO -> SINDICATO, CODEGO -> CODIGO. MAS: NAO USE ACENTOS!!!!\n",
        "\n",
        "Importante:\n",
        "Não invente nomes de colunas.\n",
        "\n",
        "Não tente acessar os dados diretamente — use apenas as ferramentas disponíveis.\n",
        "\n",
        "Não peça confirmação do usuário para regras já definidas.\n",
        "\n",
        "Execute as renomeações de forma proativa e completa.\n",
        "\n",
        "Se algum DataFrame não puder ser processado, ignore e siga para o próximo. Ao final, informe os DataFrames que foram modificados e quais colunas foram renomeadas.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Xtafn4cQR26k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consolidadorInstrucoes = \"\"\"\n",
        "Você é um analista de dados experiente em uma equipe colaborativa.\n",
        "\n",
        "Objetivo:\n",
        "Consolide as informações de vários dataframes em um único dataframe.\n",
        "\n",
        "Descrição das ferramentas:\n",
        "\n",
        "- copiarColunaSimples(dest_df_name: str, src_df_name: str, dest_column_name: str, src_column_name: str) -> dict:\n",
        "  Função para copiar os valores de um dataframe em src_column_name para o dataframe dest_df_name com o nome dest_column_name.\n",
        "- fundirColunaBaseIndexador(df_dest_name: str, df_src_name: str, index_column_name: str, columns_names_list: List[str]):\n",
        "  Função para copiar os valores das colunas columns_names do DataFrame src_df_name no dest_column_name\n",
        "  com base num indexador dado por index_column_name.\n",
        "- getdataframenames()\n",
        "  Retorna uma lista simples com os nomes dos DataFrames disponíveis.\n",
        "- getdataframeheader(df_name: str)\n",
        "  Retorna um dict com nomes de colunas e tipos do DataFrame informado. Ou vazio em caso de não existir.\n",
        "\n",
        "\n",
        "Entendedo a demanda do usuário: O usuário solicita \"Busque as informações de cargo e situação para os colaboradores\":\n",
        "1. Você comecaria analisando quais tabelas tem informacao de cargo e possui a informacao de matricula rodando:\n",
        "  -> getdataframenames() -> para saber quantos dataframes existem para ser analisados (ignorando, obviamente o DataFrameFinal)\n",
        "  -> Para cada dataframe chame getdataframeheader(df_name: str) e verifique apartir dos nomes das colunas se é plausivel executar o passo 7 abaixo para ele.\n",
        "2. Chamar a funcao fundirColunaBaseIndexador(df_dest_name: str, df_src_name: str,index_column_name: str, target_column_name:dict) para os dataframes selecionados, um por vez.\n",
        "  Para o exemplo citado acima, seria:\n",
        "  Pegando as informacoes de 'CARGO' e 'DESC. SITUACAO' no dataframe 'ATIVOS':\n",
        "        fundirColunaBaseIndexador('DataFrameFinal','ATIVOS','MATRICULA',['CARGO', 'DESC. SITUACAO'])\n",
        "  Faça similar para outros dataframes.\n",
        "  Se alguma coluna já tiver o mesmo nome no DataFrameFinal, simplesmente adicione sulfixos de uma letra _X, _Y, _Z etc..., verfique por que o pandas faz isso entao alguns sulfixos podem ja existir.\n",
        "ATENÇÃO:\n",
        "\n",
        "  - Não tente acessar dataframes por sua conta, utilize apenas essas ferramentas.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lTWadZvtoBrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMZm4c1RLskx"
      },
      "outputs": [],
      "source": [
        "# @title Define o agente operador de dataframe\n",
        "# Use one of the model constants defined earlier\n",
        "AGENT_MODEL = MODEL_GEMINI_2_5_FLASH # Starting with Gemini\n",
        "\n",
        "agenteOperadorDataFrame = Agent(\n",
        "    name=\"OperadorDataFrame\",\n",
        "    model=AGENT_MODEL, # Can be a string for Gemini or a LiteLlm object\n",
        "    description=\"Realiza operações em dataframes usando as ferramentas df.query ou df.eval, de acordo com a complexidade da tarefa.\",\n",
        "    instruction=operadorDataFrameInstrucoes,\n",
        "    tools=[querydataframe,evaldataframe, getdataframenames,getdataframeheader,criarColunaRegex,mapearValoresColunaNome], # Pass the function directly\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define o agente descritor de dataframe\n",
        "# Use one of the model constants defined earlier\n",
        "AGENT_MODEL = MODEL_GEMINI_2_5_FLASH # Starting with Gemini\n",
        "\n",
        "agenteDescritorDataFrame = Agent(\n",
        "    name=\"DescritorDataFrameV1\",\n",
        "    model=AGENT_MODEL, # Can be a string for Gemini or a LiteLlm object\n",
        "    description=\"Descreve o conteúdo de um pandas DataFrame em linguagem natural, através de reasoning e uso de ferramentas.\",\n",
        "    instruction=descritorDataFrameInstrucoes,\n",
        "    tools=[getdataframenames,getdataframeheader,adicionarDescricao], # Pass the function directly\n",
        ")\n",
        "\n",
        "#print(f\"Agent '{weather_agent.name}' created using model '{AGENT_MODEL}'.\")\n"
      ],
      "metadata": {
        "id": "BB3vAQNluV90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define o agente formatador\n",
        "# Use one of the model constants defined earlier\n",
        "AGENT_MODEL = MODEL_GEMINI_2_5_FLASH # Starting with Gemini\n",
        "\n",
        "agenteFormatadorDataFrame = Agent(\n",
        "    name=\"FormatadorDataFrameV1\",\n",
        "    model=AGENT_MODEL, # Can be a string for Gemini or a LiteLlm object\n",
        "    description=\"Agente para fazer algumas correçoes e padronizações simples em dataframes problemáticos\",\n",
        "    instruction=formatadorInstrucoes,\n",
        "    tools=[padronizarNomes,getdataframenames,getdataframeheader,getdataframestdjheader,getdataframestdmheader,renameColumn,removerLixoCabecalhos], # Pass the function directly\n",
        ")\n",
        "\n",
        "#print(f\"Agent '{weather_agent.name}' created using model '{AGENT_MODEL}'.\")\n"
      ],
      "metadata": {
        "id": "uXA1ph81ZiMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define o agente consolidador\n",
        "# Use one of the model constants defined earlier\n",
        "AGENT_MODEL = MODEL_GEMINI_2_5_FLASH # Starting with Gemini\n",
        "\n",
        "agenteConsolidadorDataFrame = Agent(\n",
        "    name=\"ConsolidadorDataFrameV1\",\n",
        "    model=AGENT_MODEL, # Can be a string for Gemini or a LiteLlm object\n",
        "    description=\"Agente para iniciar a consolidacao do dataframe final\",\n",
        "    instruction=consolidadorInstrucoes,\n",
        "    tools=[copiarColunaSimples,fundirColunaBaseIndexador,getdataframenames,getdataframeheader], # Pass the function directly\n",
        ")\n",
        "\n",
        "#print(f\"Agent '{weather_agent.name}' created using model '{AGENT_MODEL}'.\")\n"
      ],
      "metadata": {
        "id": "6hvHiUj0RLc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Setup Session Service and Runner\n",
        "\n",
        "# --- Session Management ---\n",
        "# Key Concept: SessionService stores conversation history & state.\n",
        "# InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
        "sessionOperador = InMemorySessionService()\n",
        "sessionDescritor = InMemorySessionService()\n",
        "sessionFormatador = InMemorySessionService()\n",
        "sessionConsolidador = InMemorySessionService()\n",
        "# --- Inicialização de múltiplos agentes e Runners ---\n",
        "\n",
        "acesso = {\"Operador\": 0, \"Descritor\": 1,\"Formatador\": 2,\"Consolidador\": 3}\n",
        "# Listas de identificação\n",
        "app_id_list = [\"OperadorDataFrame\", \"DescritorDataFrame\",\"FormatadorDataFrame\",\"ConsolidadorDataFrame\"]\n",
        "user_id_list = [\"operador\", \"descritor\",\"formatador\",\"consolidador\"]\n",
        "session_id_list = [\"sessao_operador\", \"sessao_descritor\",\"sessao_formatador\",\"sessao_consolidador\"]\n",
        "agent_list = [agenteOperadorDataFrame, agenteDescritorDataFrame,agenteFormatadorDataFrame,agenteConsolidadorDataFrame]\n",
        "session_service_list = [sessionOperador, sessionDescritor,sessionFormatador,sessionConsolidador]\n",
        "\n",
        "# Armazenamento de sessões e Runners\n",
        "session_list = []\n",
        "runner_list = []\n",
        "\n",
        "# Criação das sessões e dos Runners correspondentes\n",
        "for app_name, user_id, session_id, agent,session_service in zip(app_id_list, user_id_list, session_id_list, agent_list,session_service_list):\n",
        "    session = await session_service.create_session(\n",
        "        app_name=app_name,\n",
        "        user_id=user_id,\n",
        "        session_id=session_id\n",
        "    )\n",
        "    session_list.append(session)\n",
        "\n",
        "    runner = Runner(\n",
        "        agent=agent,\n",
        "        app_name=app_name,\n",
        "        session_service=session_service\n",
        "    )\n",
        "    runner_list.append(runner)"
      ],
      "metadata": {
        "id": "r8yJUosPZq8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Agent Interaction Function\n",
        "\n",
        "async def call_agent_async(query: str, runner, user_id, session_id):\n",
        "  \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
        "  print(f\"\\n>>> User Query: {query}\")\n",
        "\n",
        "  # Prepare the user's message in ADK format\n",
        "  content = types.Content(role='user', parts=[types.Part(text=query)])\n",
        "\n",
        "  final_response_text = \"Agent did not produce a final response.\" # Default\n",
        "\n",
        "  # Key Concept: run_async executes the agent logic and yields Events.\n",
        "  # We iterate through events to find the final answer.\n",
        "  async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
        "      # You can uncomment the line below to see *all* events during execution\n",
        "      #print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
        "\n",
        "      # Key Concept: is_final_response() marks the concluding message for the turn.\n",
        "      if event.is_final_response():\n",
        "          if event.content and event.content.parts:\n",
        "             # Assuming text response in the first part\n",
        "             final_response_text = event.content.parts[0].text\n",
        "          elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
        "             final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
        "          # Add more checks here if needed (e.g., specific error codes)\n",
        "          break # Stop processing events once the final response is found\n",
        "\n",
        "  print(f\"<<< Agent Response: {final_response_text}\")"
      ],
      "metadata": {
        "id": "-bIfNmG7afld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cria o DataFrameManager e carrega arquivos na memória (subir aqrquivos ai no lado se estiver no colab - Não Subir o Modelo de tabela final.. \"VR ...\")\n",
        "\n",
        "DataFrameManager = {\n",
        "\n",
        "}\n",
        "\n",
        "def list_files_in_directory(directory_path):\n",
        "    \"\"\"\n",
        "    Lists all files in a given directory.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): The path to the directory.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of filenames in the directory.\n",
        "              Returns an empty list if the directory does not exist or an error occurs.\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(directory_path):\n",
        "        print(f\"Error: The provided path '{directory_path}' is not a valid directory.\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        # os.listdir() returns a list containing the names of the entries in the directory\n",
        "        # The list is in arbitrary order.\n",
        "        all_entries = os.listdir(directory_path)\n",
        "\n",
        "        # We need to filter for files and exclude directories\n",
        "        files = [entry for entry in all_entries if os.path.isfile(os.path.join(directory_path, entry))]\n",
        "\n",
        "        return files\n",
        "    except OSError as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return []\n",
        "\n",
        "def is_excel_file(filename):\n",
        "    \"\"\"\n",
        "    Checks if a file is an Excel spreadsheet based on its extension.\n",
        "\n",
        "    Args:\n",
        "        filename (str): The name of the file to check.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the file has a common Excel extension, False otherwise.\n",
        "    \"\"\"\n",
        "    # Get the file extension\n",
        "    file_extension = os.path.splitext(filename)[1].lower()\n",
        "\n",
        "    # Check if the extension is in our list of common Excel extensions\n",
        "    excel_extensions = ['.xlsx', '.xls', '.xlsm']\n",
        "\n",
        "    return file_extension in excel_extensions\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "target_dir = os.path.join(current_dir, \"\")\n",
        "files_list = list_files_in_directory(target_dir)\n",
        "for file in  files_list:\n",
        "    if is_excel_file(file):\n",
        "        df = pd.read_excel(os.path.join(target_dir, file))\n",
        "        if df is not None:\n",
        "                           DataFrameManager.update({(os.path.splitext(file)[0]): df})\n",
        "        else:\n",
        "                           print(f\"Error while trying to create a new dataframe from file {os.path.join(target_dir, file)}\")\n"
      ],
      "metadata": {
        "id": "K63LqezXBt1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Iniciando o Tratamento dos Arquivos com Agentes:\n",
        "\n",
        "# Iniciando o Agente formatador para trabalhar os nomes das colunas:\n",
        "# To do: Se organizar a execucao deles em um loop poderia rodar a funcao de padronizacao primaria fora do agente reduzindo a carga de processamento: Ela é universal e não precisa do agente...\n",
        "#        Já as funções posteriores precisam de raciocínio para serem ativadas corretamente.\n",
        "\n",
        "async def run_conversation():\n",
        "    # Chama o formatador reforçando algumas informações de conhecimento prévio\n",
        "    await call_agent_async(\"Padronize os Dataframes disponíveis. Regras para desambiguação de nomes: Cadastro: renomeie para 'MATRICULA'. TITULO DO CARGO e variantes disso:  renomeie para 'CARGO'. IMPORTANTE: Lembre-se de corrigir erros de português\",\n",
        "                                       runner=runner_list[acesso['Formatador']],\n",
        "                                       user_id=user_id_list[acesso['Formatador']],\n",
        "                                       session_id=session_id_list[acesso['Formatador']])\n",
        "    # Algumas vezes ele tem preguiça e deixa passar erros de português... por garantia vamos pedir de novo:\n",
        "    await call_agent_async(\"Cheque mais uma vez os cabeçalhos buscando erros de poertuguês\",\n",
        "                                       runner=runner_list[acesso['Formatador']],\n",
        "                                       user_id=user_id_list[acesso['Formatador']],\n",
        "                                       session_id=session_id_list[acesso['Formatador']])\n",
        "    # Chama o operador para fazer algumas operações com colunas (removido as ferramentas query e eval que não estavam ajudando)\n",
        "    await call_agent_async(\"Para 'Base dias uteis': Crie uma coluna 'ESTADO_SIGLA'com base no nome do sindicato que pode ser encontrado na coluna 'SINDICATO'. Realize a extração da sigla do nome do sindicato. Use apenas o dataframe 'Base dias uteis' NÃO opere sobre o DataFrameFinal.\",\n",
        "                                       runner=runner_list[0],\n",
        "                                       user_id=user_id_list[0],\n",
        "                                       session_id=session_id_list[0])\n",
        "    # Como estava tendo problemas de chaves, e também para evitar alucinações vamos quebrar os pedidos em etapas (talvez fosse interessante resetar o contexto aqui? -> tokens????) (Cada agente tem sua in memory session isolada....)\n",
        "    await call_agent_async(\"Para 'Base dias uteis': Crie a coluna ESTADO com base na coluna 'ESTADO_SIGLA' para o nome de estado. Exemplo: PR -> Paraná. Use apenas o dataframe 'Base dias uteis' NÃO opere sobre o DataFrameFinal.\",\n",
        "                                       runner=runner_list[0],\n",
        "                                       user_id=user_id_list[0],\n",
        "                                       session_id=session_id_list[0])\n",
        "    # Agora chamamos o consolidador com um set de ferramentas diferente para juntas informações: (Nota: Removi as funcoes para iniciar a criação do dataframe final ele estava se confundindo e copiando informacao no DataFrameFinal)\n",
        "    await call_agent_async(\"Funda os dados de 'Base sindicato x valor' no dataframe 'Base dias uteis', trazendo a coluna 'VALOR' e tendo a coluna 'ESTADO' como indexador/coluna em comum. Use apenas o dataframe 'Base dias uteis' NÃO opere sobre o DataFrameFinal.\",\n",
        "                                       runner=runner_list[3],\n",
        "                                       user_id=user_id_list[3],\n",
        "                                       session_id=session_id_list[3])\n",
        "\n",
        "\n",
        "# Execute the conversation using await in an async context (like Colab/Jupyter)\n",
        "\n",
        "await run_conversation()"
      ],
      "metadata": {
        "id": "ouW1VHvidlQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a337b6cf-6fe1-4b50-b6ce-b39868015bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> User Query: Padronize os Dataframes disponíveis. Regras para desambiguação de nomes: Cadastro: renomeie para 'MATRICULA'. TITULO DO CARGO e variantes disso:  renomeie para 'CARGO'. IMPORTANTE: Lembre-se de corrigir erros de português\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<< Agent Response: DataFrames modificados e colunas renomeadas:\n",
            "\n",
            "*   **EXTERIOR**: `CADASTRO` -> `MATRICULA`\n",
            "*   **APRENDIZ**: `TITULO DO CARGO` -> `CARGO`\n",
            "*   **Base dias uteis**:\n",
            "    *   `removerLixoCabecalhos()` foi aplicado.\n",
            "    *   `DIAS UTEIS ` -> `DIAS UTEIS`\n",
            "*   **ATIVOS**: `TITULO DO CARGO` -> `CARGO`\n",
            "*   **ESTÁGIO**: `TITULO DO CARGO` -> `CARGO`\n",
            "\n",
            ">>> User Query: Cheque mais uma vez os cabeçalhos buscando erros de poertuguês\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<< Agent Response: A coluna `SINDICADO` no DataFrame `Base dias uteis` foi renomeada para `SINDICATO`.\n",
            "\n",
            ">>> User Query: Para 'Base dias uteis': Crie uma coluna 'ESTADO_SIGLA'com base no nome do sindicato que pode ser encontrado na coluna 'SINDICATO'. Realize a extração da sigla do nome do sindicato. Use apenas o dataframe 'Base dias uteis' NÃO opere sobre o DataFrameFinal.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<< Agent Response: {\"status\": \"success\", \"newdf\": \"Base dias uteis\", \"error\": None}\n",
            "\n",
            ">>> User Query: Para 'Base dias uteis': Crie a coluna ESTADO com base na coluna 'ESTADO_SIGLA' para o nome de estado. Exemplo: PR -> Paraná. Use apenas o dataframe 'Base dias uteis' NÃO opere sobre o DataFrameFinal.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<< Agent Response: {\"status\": \"success\", \"newdf\": \"Base dias uteis\", \"error\": None}\n",
            "\n",
            ">>> User Query: Funda os dados de 'Base sindicato x valor' no dataframe 'Base dias uteis', trazendo a coluna 'VALOR' e tendo a coluna 'ESTADO' como indexador/coluna em comum. Use apenas o dataframe 'Base dias uteis' NÃO opere sobre o DataFrameFinal.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<< Agent Response: As informações da coluna 'VALOR' do dataframe 'Base sindicato x valor' foram fundidas com sucesso no dataframe 'Base dias uteis', utilizando 'ESTADO' como indexador.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Mais funções auxiliares\n",
        "################################################################################\n",
        "# Função para automatizar um merge de info de dois dataframes com copia de todas as colunas\n",
        "\n",
        "################################################################################\n",
        "\n",
        "def simplemerge(\n",
        "    df_dest: pd.DataFrame,\n",
        "    df_source: pd.DataFrame,\n",
        "    chave: str,\n",
        "    how: str = \"left\"\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Faz merge entre df_dest e df_source, renomeando colunas duplicadas do df_source com sufixos numerados.\n",
        "\n",
        "    Args:\n",
        "        df_dest (pd.DataFrame): DataFrame principal.\n",
        "        df_source (pd.DataFrame): DataFrame complementar.\n",
        "        chave (str): Coluna usada como chave de junção.\n",
        "        how (str): Tipo de merge (default: 'left').\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Resultado do merge com colunas renomeadas dinamicamente.\n",
        "    \"\"\"\n",
        "    if chave not in df_dest.columns or chave not in df_source.columns:\n",
        "        print(f\"[AVISO] Chave '{chave}' não encontrada em ambos os DataFrames.\")\n",
        "        return df_dest\n",
        "\n",
        "    # Renomeia colunas duplicadas do df_source\n",
        "    colunas_renomeadas = {}\n",
        "    for col in df_source.columns:\n",
        "        if col == chave:\n",
        "            continue\n",
        "        novo_nome = col\n",
        "        contador = 1\n",
        "        while novo_nome in df_dest.columns or novo_nome in colunas_renomeadas.values():\n",
        "            novo_nome = f\"{col}_{contador}\"\n",
        "            contador += 1\n",
        "        colunas_renomeadas[col] = novo_nome\n",
        "\n",
        "    df_source_renomeado = df_source.rename(columns=colunas_renomeadas)\n",
        "\n",
        "    return pd.merge(df_dest, df_source_renomeado, on=chave, how=how)\n",
        "\n",
        "################################################################################\n",
        "# Funções para fazer merge de colunas repedidas...\n",
        "# A primeira checa o tipo, a segunda não.\n",
        "# Quando for usar com um agente melhor usar a primeira\n",
        "# Criar outro agente para usar a segunda só nas colunas tipo anotação\n",
        "# Mas para isso o agente descritor tem que estar 100% operacional e\n",
        "# conseguir descrever colunas também.\n",
        "###############################################################################\n",
        "\n",
        "def consolidar_colunas(\n",
        "    nome_data_frame: str,\n",
        "    nome_coluna_destino: str,\n",
        "    colunas_a_consolidar: List[str],\n",
        "    operador: str\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Consolida colunas de um DataFrame usando operador definido, com tratamento para texto e números.\n",
        "    Após a consolidação, remove as colunas originais utilizadas e renomeia a coluna gerada.\n",
        "\n",
        "    Args:\n",
        "        nome_data_frame (str): Nome do DataFrame no DataFrameManager.\n",
        "        nome_coluna_destino (str): Nome da coluna final consolidada.\n",
        "        colunas_a_consolidar (List[str]): Lista de colunas a consolidar.\n",
        "        operador (str): Operador de consolidação ('|', '+', '-', '*', '/').\n",
        "\n",
        "    Returns:\n",
        "        dict: {\"status\": \"success\", \"df_name\": <nome>, \"error\": None} ou {\"status\": \"error\", ...}\n",
        "    \"\"\"\n",
        "    df = DataFrameManager.get(nome_data_frame)\n",
        "    if df is None:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": f\"DataFrame '{nome_data_frame}' não encontrado.\"}\n",
        "\n",
        "    try:\n",
        "        # Verifica se todas as colunas existem\n",
        "        colunas_invalidas = [col for col in colunas_a_consolidar if col not in df.columns]\n",
        "        if colunas_invalidas:\n",
        "            return {\"status\": \"error\", \"df_name\": None, \"error\": f\"Colunas não encontradas: {colunas_invalidas}\"}\n",
        "\n",
        "        # Cria nome temporário seguro\n",
        "        nome_temporario = f\"__temp_{nome_coluna_destino}__\"\n",
        "        while nome_temporario in df.columns:\n",
        "            nome_temporario += \"_\"\n",
        "\n",
        "        # Detecta tipo dominante (texto ou numérico)\n",
        "        tipos = df[colunas_a_consolidar].dtypes\n",
        "        if all(tipos.apply(lambda t: pd.api.types.is_string_dtype(t))):\n",
        "            # Consolidação textual\n",
        "            def concat_texto(row):\n",
        "                valores = [str(row[col]).strip() for col in colunas_a_consolidar\n",
        "                           if pd.notnull(row[col]) and str(row[col]).strip() != \"\"]\n",
        "                return operador.join(valores) if valores else np.nan\n",
        "\n",
        "            df[nome_temporario] = df.apply(concat_texto, axis=1)\n",
        "\n",
        "        elif all(tipos.apply(lambda t: pd.api.types.is_numeric_dtype(t))):\n",
        "            # Consolidação numérica\n",
        "            if operador == \"+\":\n",
        "                df[nome_temporario] = df[colunas_a_consolidar].sum(axis=1, skipna=True)\n",
        "            elif operador == \"*\":\n",
        "                df[nome_temporario] = df[colunas_a_consolidar].prod(axis=1, skipna=True)\n",
        "            elif operador == \"-\":\n",
        "                df[nome_temporario] = df[colunas_a_consolidar].iloc[:, 0]\n",
        "                for col in colunas_a_consolidar[1:]:\n",
        "                    df[nome_temporario] -= df[col].fillna(0)\n",
        "            elif operador == \"/\":\n",
        "                df[nome_temporario] = df[colunas_a_consolidar].iloc[:, 0]\n",
        "                for col in colunas_a_consolidar[1:]:\n",
        "                    df[nome_temporario] = df[nome_temporario] / df[col].replace(0, np.nan)\n",
        "            else:\n",
        "                return {\"status\": \"error\", \"df_name\": None, \"error\": f\"Operador numérico inválido: '{operador}'\"}\n",
        "        else:\n",
        "            return {\"status\": \"error\", \"df_name\": None, \"error\": \"Tipos mistos: não é possível consolidar texto com números.\"}\n",
        "\n",
        "        # Remove colunas originais\n",
        "        df.drop(columns=colunas_a_consolidar, inplace=True)\n",
        "\n",
        "        # Renomeia coluna temporária para destino\n",
        "        df.rename(columns={nome_temporario: nome_coluna_destino}, inplace=True)\n",
        "\n",
        "        DataFrameManager.update({nome_data_frame: df})\n",
        "        return {\"status\": \"success\", \"df_name\": nome_data_frame, \"error\": None}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": str(e)}\n",
        "\n",
        "def consolidar_colunas_como_texto(\n",
        "    nome_data_frame: str,\n",
        "    nome_coluna_destino: str,\n",
        "    colunas_a_consolidar: List[str],\n",
        "    operador: str\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Consolida colunas de um DataFrame ignorando tipos, convertendo tudo para string e concatenando com operador.\n",
        "    Após a consolidação, remove as colunas originais utilizadas e renomeia a coluna gerada.\n",
        "\n",
        "    Args:\n",
        "        nome_data_frame (str): Nome do DataFrame no DataFrameManager.\n",
        "        nome_coluna_destino (str): Nome da coluna final consolidada.\n",
        "        colunas_a_consolidar (List[str]): Lista de colunas a consolidar.\n",
        "        operador (str): Operador de concatenação (ex: '|', '-', etc.).\n",
        "\n",
        "    Returns:\n",
        "        dict: {\"status\": \"success\", \"df_name\": <nome>, \"error\": None} ou {\"status\": \"error\", ...}\n",
        "    \"\"\"\n",
        "    df = DataFrameManager.get(nome_data_frame)\n",
        "    if df is None:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": f\"DataFrame '{nome_data_frame}' não encontrado.\"}\n",
        "\n",
        "    try:\n",
        "        # Verifica se todas as colunas existem\n",
        "        colunas_invalidas = [col for col in colunas_a_consolidar if col not in df.columns]\n",
        "        if colunas_invalidas:\n",
        "            return {\"status\": \"error\", \"df_name\": None, \"error\": f\"Colunas não encontradas: {colunas_invalidas}\"}\n",
        "\n",
        "        # Cria nome temporário seguro\n",
        "        nome_temporario = f\"__temp_{nome_coluna_destino}__\"\n",
        "        while nome_temporario in df.columns:\n",
        "            nome_temporario += \"_\"\n",
        "\n",
        "        # Consolidação forçada como texto\n",
        "        def concat_forcado(row):\n",
        "            valores = [str(row[col]).strip() for col in colunas_a_consolidar if pd.notnull(row[col])]\n",
        "            return operador.join(valores) if valores else \"\"\n",
        "\n",
        "        df[nome_temporario] = df.apply(concat_forcado, axis=1)\n",
        "\n",
        "        # Remove colunas originais\n",
        "        df.drop(columns=colunas_a_consolidar, inplace=True)\n",
        "\n",
        "        # Renomeia coluna temporária para destino\n",
        "        df.rename(columns={nome_temporario: nome_coluna_destino}, inplace=True)\n",
        "\n",
        "        DataFrameManager.update({nome_data_frame: df})\n",
        "        return {\"status\": \"success\", \"df_name\": nome_data_frame, \"error\": None}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"df_name\": None, \"error\": str(e)}\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Função para juntar todos os dados em todos os dataframes que possuam o mesmo\n",
        "# indexador.\n",
        "# Aqui está hard coded mas pode ser \"agentificado\".\n",
        "# O agente deve identificar o indexador a ser usado e passar como parâmetro\n",
        "# Por hora não conseguiremos colocar um agente nessa parte\n",
        "# Obs: Fica mais fácil se o usuario digitar o indexador...chamar o agente duas\n",
        "# vezes, uma para tratar dados de MATRICULA outro para tratar os dados de\n",
        "# SINDICATO, ou se o agente descritor estiver 100% funcional capaz de descrever\n",
        "# colunas\n",
        "################################################################################\n",
        "\n",
        "def consolidar_dados():\n",
        "  # Com as tabelas arrumadas a consolidacao é procedural\n",
        "  matriculas_list = []\n",
        "  if(DataFrameManager.get('DataFrameFinal') is not None):\n",
        "    DataFrameManager.pop('DataFrameFinal')\n",
        "  # Loop through each DataFrame in the dictionary\n",
        "  for key, value in DataFrameManager.items():\n",
        "      # Check if the DataFrame has a 'MATRICULA' column\n",
        "      if 'MATRICULA' in value.columns:\n",
        "          # If it exists, extend the list with the values from that column\n",
        "          matriculas_list.extend(value['MATRICULA'].tolist())\n",
        "\n",
        "  # Create a new DataFrame from the list of all matriculas\n",
        "  df = pd.DataFrame(matriculas_list, columns=['MATRICULA'])\n",
        "\n",
        "  # Remove duplicate values to get only unique matriculas\n",
        "  df = df.drop_duplicates()\n",
        "  print(df.info())\n",
        "\n",
        "\n",
        "  for src_df in DataFrameManager.values():\n",
        "      df = simplemerge(df,src_df,'MATRICULA','left')\n",
        "\n",
        "  df_sindicato = DataFrameManager.get('Base dias uteis')\n",
        "\n",
        "  df = pd.merge(\n",
        "      df,\n",
        "      df_sindicato[['SINDICATO', 'VALOR', 'DIAS UTEIS']],\n",
        "      on='SINDICATO',\n",
        "      how='left'\n",
        "  )\n",
        "  DataFrameManager.update({'DataFrameFinal': df})\n",
        "\n"
      ],
      "metadata": {
        "id": "VDRpMVC9E7BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# Aqui já temos todos os dados na tabela final bastando realizar consolidação,\n",
        "# padronização, cálculos e limpezas.\n",
        "# A maioria dessas etapas não seriam bem relizadas pela llm, exceto aquelas em\n",
        "# que a ferramenta poderia ser melhor aproveitada com a llm para ganhar\n",
        "# resistência a mudanças em alguns nomes críticos, como MATRICULA virar REGISTRO\n",
        "# ou coisa similar. (Se bem que la no agente formatador podemos simplesmente\n",
        "# pedir que seja mantida nossa convenção....\n",
        "# O que um agente poderia também agregar nessa etapa é recegber do usuário um\n",
        "# template ou por conversa definir o fomrato do output final.\n",
        "# Uma outra melhoria seria cada agente responsavel por uma regra de negócio que\n",
        "# pode ser discutida em tempo de execução por exemplo, antes do resultaod final.\n",
        "# Mas não cnseguiremos ainda nessa versão.\n",
        "################################################################################\n",
        "def iniciar_calculos():\n",
        "  # Puxar todas as informações para planilha final\n",
        "  consolidar_dados()\n",
        "  #Agora consolidar colunas:\n",
        "\n",
        "  print(consolidar_colunas(\"DataFrameFinal\",'CARGO',['CARGO', 'CARGO_1','CARGO_2', 'CARGO_3'],' | '))\n",
        "  print(consolidar_colunas(\"DataFrameFinal\",'DESC. SITUACAO',['DESC. SITUACAO','DESC. SITUACAO_1', 'DESC. SITUACAO_2'],' | '))\n",
        "\n",
        "  df = DataFrameManager.get('DataFrameFinal').copy()\n",
        "\n",
        "  df.rename(columns={\"VALOR_x\": \"VALOR TOTAL\"}, inplace=True)\n",
        "  df.rename(columns={\"VALOR_y\": \"VALOR DIARIO VR\"}, inplace=True)\n",
        "\n",
        "  # Aqui removemos todos os não elegíveis pelas regras de negócio (exceto profissionais no exterior):\n",
        "  df = df.loc[\n",
        "    ~df[\"CARGO\"]\n",
        "    .astype(str)\n",
        "    .map(unidecode)\n",
        "    .str.upper()\n",
        "    .str.contains(\"ESTAGIARIO\", na=False)\n",
        "  ]\n",
        "  df = df.loc[\n",
        "      ~df[\"CARGO\"]\n",
        "      .astype(str)\n",
        "      .map(unidecode)\n",
        "      .str.upper()\n",
        "      .str.contains(\"APRENDIZ\", na=False)\n",
        "  ]\n",
        "  df = df.loc[\n",
        "      ~df[\"DESC. SITUACAO\"]\n",
        "      .astype(str)\n",
        "      .map(unidecode)\n",
        "      .str.upper()\n",
        "      .str.contains(\"ATESTADO\", na=False)\n",
        "  ]\n",
        "  df = df.loc[\n",
        "      ~df[\"DESC. SITUACAO\"]\n",
        "      .astype(str)\n",
        "      .map(unidecode)\n",
        "      .str.upper()\n",
        "      .str.contains(\"MATERNIDADE\", na=False)\n",
        "  ]\n",
        "  df = df.loc[\n",
        "      ~df[\"DESC. SITUACAO\"]\n",
        "      .astype(str)\n",
        "      .map(unidecode)\n",
        "      .str.upper()\n",
        "      .str.contains(\"AUXILIO\", na=False)\n",
        "  ]\n",
        "  df = df.loc[df['COMUNICADO DE DESLIGAMENTO'] != 'OK']\n",
        "\n",
        "  # Foi notado que mesmo após todas as remoções e correções alguns não possuiuam info sindical\n",
        "  df[\"DIAS UTEIS\"] = pd.to_numeric(df[\"DIAS UTEIS\"], errors=\"coerce\").fillna(0)\n",
        "  df.loc[df[\"DIAS UTEIS\"] == 0, \"DIAS UTEIS\"] = 22\n",
        "\n",
        "  df.loc[df[\"SINDICATO\"].isna() | (df[\"SINDICATO\"].astype(str).str.strip() == \"\"), \"OBS GERAL\"] = \"ATENCAO COLABORADOR SEM INFO SINDICATO. PREENCHENDO COM: DADOS SP\"\n",
        "\n",
        "  df[\"VALOR DIARIO VR\"] = pd.to_numeric(df[\"VALOR DIARIO VR\"], errors=\"coerce\").fillna(0)\n",
        "  df.loc[df[\"VALOR DIARIO VR\"] == 0, \"VALOR DIARIO VR\"] = 37.50\n",
        "\n",
        "  # Agora fazemos os cálculos com as regras definidas\n",
        "  # interpretando que deverá serfeito calculo proporcional\n",
        "  # ao dias uteis:\n",
        "  df[\"COMPETENCIA\"] = \"05/2025\" # cria coluna competencia\n",
        "  # 1. Converter datas\n",
        "  df[\"ADMISSAO\"] = pd.to_datetime(df[\"ADMISSAO\"], errors=\"coerce\", dayfirst=True)\n",
        "  df[\"DATA DEMISSAO\"] = pd.to_datetime(df[\"DATA DEMISSAO\"], errors=\"coerce\", dayfirst=True)\n",
        "  df[\"COMPETENCIA\"] = pd.to_datetime(\"01/\" + df[\"COMPETENCIA\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
        "\n",
        "  # 2. Definir início e fim do mês de cálculo\n",
        "  df[\"INICIO_MES\"] = (df[\"COMPETENCIA\"] - pd.DateOffset(months=1)).apply(lambda x: x.replace(day=1))\n",
        "  df[\"FIM_MES\"] = df[\"INICIO_MES\"] + MonthEnd(0)\n",
        "\n",
        "  # 3. Calcular entrada e saída no mês\n",
        "  df[\"ENTRADA_MES\"] = df[[\"ADMISSAO\", \"INICIO_MES\"]].max(axis=1)\n",
        "  df[\"SAIDA_MES\"] = df[[\"DATA DEMISSAO\", \"FIM_MES\"]].min(axis=1)\n",
        "  df[\"SAIDA_MES\"] = df[\"SAIDA_MES\"].fillna(df[\"FIM_MES\"])\n",
        "\n",
        "  # 4. Calcular dias trabalhados no mês\n",
        "  df[\"DIAS_TRABALHADOS\"] = (df[\"SAIDA_MES\"] - df[\"ENTRADA_MES\"]).dt.days + 1\n",
        "  df[\"DIAS_TRABALHADOS\"] = df[\"DIAS_TRABALHADOS\"].clip(lower=0)\n",
        "\n",
        "  # 5. Descontar férias\n",
        "  df[\"DIAS DE FERIAS\"] = pd.to_numeric(df[\"DIAS DE FERIAS\"], errors=\"coerce\").fillna(0)\n",
        "  df[\"DIAS_TRABALHADOS_LIQUIDO\"] = df[\"DIAS_TRABALHADOS\"] - df[\"DIAS DE FERIAS\"]\n",
        "  df[\"DIAS_TRABALHADOS_LIQUIDO\"] = df[\"DIAS_TRABALHADOS_LIQUIDO\"].clip(lower=0)\n",
        "\n",
        "  # 6. Garantir que DIAS UTEIS seja numérico\n",
        "  df[\"DIAS UTEIS\"] = pd.to_numeric(df[\"DIAS UTEIS\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "  # 7. Calcular total de dias corridos no mês\n",
        "  df[\"DIAS_TOTAIS_MES\"] = (df[\"FIM_MES\"] - df[\"INICIO_MES\"]).dt.days + 1\n",
        "\n",
        "  # 8. Calcular dias úteis proporcionais ao tempo trabalhado\n",
        "  df[\"DIAS\"] = (\n",
        "      df[\"DIAS UTEIS\"] / df[\"DIAS_TOTAIS_MES\"]\n",
        "  ) * df[\"DIAS_TRABALHADOS_LIQUIDO\"]\n",
        "\n",
        "  df[\"DIAS\"] = df[\"DIAS\"].round(0).clip(lower=0)\n",
        "\n",
        "  # Calculos DE DIAS terminados, vamos jogar o lixo fora\n",
        "  df.drop(columns=[\n",
        "    \"INICIO_MES\", \"FIM_MES\", \"ENTRADA_MES\", \"SAIDA_MES\",\"EMPRESA\",\n",
        "    \"DIAS_TRABALHADOS\", \"DIAS_TRABALHADOS_LIQUIDO\", \"DIAS_TOTAIS_MES\",\n",
        "    \"DIAS UTEIS\", \"DIAS DE FERIAS\", \"DATA DEMISSAO\", \"COMUNICADO DE DESLIGAMENTO\"\n",
        "  ], inplace=True)\n",
        "\n",
        "  DataFrameManager.update({'DataFrameFinal': df})\n",
        "  # As colunas de anotações não vamos jogar fora, mas concatenar tudo na coluna de OBS GERAL:\n",
        "  consolidar_colunas_como_texto(\"DataFrameFinal\",'OBS GERAL',['OBS GERAL', 'UNNAMED: 2','UNNAMED: 3', 'NA COMPRA?','NA COMPRA?_1','UNNAMED: 3_1','DESC. SITUACAO'],' | ')\n",
        "  # Agora sim partimos para a etapa final dos cálculos:\n",
        "\n",
        "  df[\"DIAS\"] = pd.to_numeric(df[\"DIAS\"], errors=\"coerce\").fillna(0)\n",
        "  df[\"VALOR DIARIO VR\"] = pd.to_numeric(df[\"VALOR DIARIO VR\"], errors=\"coerce\").fillna(0)\n",
        "  df[\"VALOR TOTAL\"] = pd.to_numeric(df[\"VALOR TOTAL\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "  df[\"VALOR TOTAL\"] = df.apply(\n",
        "      lambda row: row[\"DIAS\"] * row[\"VALOR DIARIO VR\"] if row[\"VALOR TOTAL\"] == 0 else row[\"VALOR TOTAL\"],\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "  df[\"Custo empresa\"] = df[\"VALOR TOTAL\"] * 0.8\n",
        "  df[\"Desconto profissional\"] = df[\"VALOR TOTAL\"] * 0.2\n",
        "\n",
        "\n",
        "  # Por último e não menos importante vaos formatar a saída conforme desejado:\n",
        "  # Todo: fazer outro agente formatador formatado pra essa etapa:\n",
        "  df.rename(columns={\n",
        "    \"MATRICULA\": \"Matricula\",\n",
        "    \"ADMISSAO\": \"Admissão\",\n",
        "    \"SINDICATO\": \"Sindicato do Colaborador\",\n",
        "    \"VALOR TOTAL\": \"TOTAL\",\n",
        "    \"COMPETENCIA\": \"Competência\",\n",
        "    \"DIAS\": \"Dias\",\n",
        "    \"VALOR DIARIO VR\": \"VALOR DIÁRIO VR\",\n",
        "    \"OBS GERAL\": \"OBS GERAL\"\n",
        "  }, inplace=True)\n",
        "\n",
        "  df = df[df[\"TOTAL\"] != 0]\n",
        "\n",
        "  df = df[[\n",
        "      \"Matricula\", \"Admissão\", \"Sindicato do Colaborador\", \"Competência\", \"Dias\",\n",
        "      \"VALOR DIÁRIO VR\", \"TOTAL\", \"Custo empresa\", \"Desconto profissional\", \"OBS GERAL\"\n",
        "  ]]\n",
        "\n",
        "  # Gera o arquivo excem no DRIVE:\n",
        "  df.to_excel('VR MENSAL 05.2025.xlsx', index=False)\n",
        "\n",
        "iniciar_calculos()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1C-ovOca4je",
        "outputId": "02220f8d-9b5f-4562-d6ed-dc652e19dc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1936 entries, 0 to 2092\n",
            "Data columns (total 1 columns):\n",
            " #   Column     Non-Null Count  Dtype\n",
            "---  ------     --------------  -----\n",
            " 0   MATRICULA  1936 non-null   int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 30.2 KB\n",
            "None\n",
            "[AVISO] Chave 'MATRICULA' não encontrada em ambos os DataFrames.\n",
            "[AVISO] Chave 'MATRICULA' não encontrada em ambos os DataFrames.\n",
            "{'status': 'success', 'df_name': 'DataFrameFinal', 'error': None}\n",
            "{'status': 'success', 'df_name': 'DataFrameFinal', 'error': None}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}